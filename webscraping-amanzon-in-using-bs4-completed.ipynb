{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77bab31d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-11-13T20:30:56.679818Z",
     "iopub.status.busy": "2022-11-13T20:30:56.678835Z",
     "iopub.status.idle": "2022-11-13T20:30:56.692183Z",
     "shell.execute_reply": "2022-11-13T20:30:56.691195Z"
    },
    "papermill": {
     "duration": 0.021594,
     "end_time": "2022-11-13T20:30:56.694652",
     "exception": false,
     "start_time": "2022-11-13T20:30:56.673058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4deac36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:30:56.701385Z",
     "iopub.status.busy": "2022-11-13T20:30:56.701067Z",
     "iopub.status.idle": "2022-11-13T20:30:56.883434Z",
     "shell.execute_reply": "2022-11-13T20:30:56.882549Z"
    },
    "papermill": {
     "duration": 0.188506,
     "end_time": "2022-11-13T20:30:56.886035",
     "exception": false,
     "start_time": "2022-11-13T20:30:56.697529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc89461d",
   "metadata": {
    "papermill": {
     "duration": 0.002282,
     "end_time": "2022-11-13T20:30:56.891115",
     "exception": false,
     "start_time": "2022-11-13T20:30:56.888833",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Defining fucntions\n",
    "We can define a function to extract Product title. This involves getting the outer Tag Object, inner navigatable string object and title as a string value.Creating these functions will make it easy for us by just calling them when ever needed during our scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd7f8b47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:30:56.898054Z",
     "iopub.status.busy": "2022-11-13T20:30:56.897295Z",
     "iopub.status.idle": "2022-11-13T20:30:56.910263Z",
     "shell.execute_reply": "2022-11-13T20:30:56.909156Z"
    },
    "papermill": {
     "duration": 0.019179,
     "end_time": "2022-11-13T20:30:56.912750",
     "exception": false,
     "start_time": "2022-11-13T20:30:56.893571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to extract product title\n",
    "def get_title(soup):\n",
    "    try:\n",
    "        #Outer tag Object\n",
    "        title = soup.find(\"span\", attrs={\"id\":'productTitle'})\n",
    "        #Inner NavigatableString Object\n",
    "        title_value = title.text\n",
    "        #Title as String Value\n",
    "        title_string = title_value.strip()\n",
    "    \n",
    "    except AttributeError:\n",
    "        title_string = \"\"\n",
    "    return title_string\n",
    "\n",
    "\n",
    "# Function to extract Product Price\n",
    "def get_price(soup):\n",
    "\n",
    "    try:\n",
    "        price = soup.find(\"span\", attrs={'id':'priceblock_ourprice'}).string.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "\n",
    "        try:\n",
    "            # If there is some deal price\n",
    "            price = soup.find(\"span\", attrs={'id':'priceblock_dealprice'}).string.strip()\n",
    "\n",
    "        except:\n",
    "            price = \"\"\n",
    "\n",
    "    return price\n",
    "\n",
    "# Function to extract Product Rating\n",
    "def get_rating(soup):\n",
    "\n",
    "    try:\n",
    "        rating = soup.find(\"i\", attrs={'class':'a-icon a-icon-star a-star-4-5'}).string.strip()\n",
    "    \n",
    "    except AttributeError:\n",
    "        try:\n",
    "            rating = soup.find(\"span\", attrs={'class':'a-icon-alt'}).string.strip()\n",
    "        except:\n",
    "            rating = \"\"\t\n",
    "\n",
    "    return rating\n",
    "\n",
    "# Function to extract Number of User Reviews\n",
    "def get_review_count(soup):\n",
    "    try:\n",
    "        review_count = soup.find(\"span\", attrs={'id':'acrCustomerReviewText'}).string.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "        review_count = \"\"\t\n",
    "\n",
    "    return review_count\n",
    "\n",
    "# Function to extract Availability Status\n",
    "def get_availability(soup):\n",
    "    try:\n",
    "        available = soup.find(\"div\", attrs={'id':'availability'})\n",
    "        available = available.find(\"span\").string.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "        available = \"Not Available\"\t\n",
    "\n",
    "    return available\n",
    " \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc3ad029",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:30:56.919623Z",
     "iopub.status.busy": "2022-11-13T20:30:56.919288Z",
     "iopub.status.idle": "2022-11-13T20:31:17.247257Z",
     "shell.execute_reply": "2022-11-13T20:31:17.246333Z"
    },
    "papermill": {
     "duration": 20.334356,
     "end_time": "2022-11-13T20:31:17.249818",
     "exception": false,
     "start_time": "2022-11-13T20:30:56.915462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # add your user agent \n",
    "    HEADERS = ({'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36 Edg/107.0.1418.42', 'Accept-Language': 'en-US, en;q=0.5'})\n",
    "\n",
    "    # The webpage URL\n",
    "    URL = \"https://www.amazon.in/s?k=ps5+console&rh=n%3A976460031%2Cp_36%3A1741396031&dc&ds=v1%3Axafe%2FgyRPuL4T2kmwIp6CX%2B0JadN6DlQKyDerdH8dLU&content-id=amzn1.sym.c16802f7-e9f2-4a7a-ace2-b13748bc8783%3Aamzn1.sym.c16802f7-e9f2-4a7a-ace2-b13748bc8783&pd_rd_r=c8b37f64-54c3-471c-996c-cd3303d6eb80&pd_rd_w=4ODOt&pd_rd_wg=5mbVF&pf_rd_p=c16802f7-e9f2-4a7a-ace2-b13748bc8783&pf_rd_r=3RNSR7XSYP40J8P2DWBR&qid=1668370027&rnid=1741393031&ref=sr_nr_p_36_3\"\n",
    "\n",
    "    # HTTP Request\n",
    "    webpage = requests.get(URL, headers=HEADERS)\n",
    "\n",
    "    # Soup Object containing all data\n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "\n",
    "    # Fetch links as List of Tag Objects\n",
    "    links = soup.find_all(\"a\", attrs={'class':'a-link-normal s-no-outline'})\n",
    "\n",
    "    # Store the links\n",
    "    links_list = []\n",
    "\n",
    "    # Loop for extracting links from Tag Objects\n",
    "    for link in links:\n",
    "            links_list.append(link.get('href'))\n",
    "\n",
    "    d = {\"title\":[], \"price\":[], \"rating\":[], \"reviews\":[],\"availability\":[]}\n",
    "    \n",
    "    # Loop for extracting product details from each link \n",
    "    for link in links_list:\n",
    "        new_webpage = requests.get(\"https://www.amazon.com\" + link, headers=HEADERS)\n",
    "\n",
    "        new_soup = BeautifulSoup(new_webpage.content, \"html.parser\")\n",
    "\n",
    "        # Function calls to display all necessary product information\n",
    "        d['title'].append(get_title(new_soup))\n",
    "        d['price'].append(get_price(new_soup))\n",
    "        d['rating'].append(get_rating(new_soup))\n",
    "        d['reviews'].append(get_review_count(new_soup))\n",
    "        d['availability'].append(get_availability(new_soup))\n",
    "\n",
    "    \n",
    "    amazon_df = pd.DataFrame.from_dict(d)\n",
    "    amazon_df['title'].replace('', np.nan, inplace=True)\n",
    "    amazon_df = amazon_df.dropna(subset=['title'])\n",
    "    amazon_df.to_csv(\"amazon_data.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11ca51ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:31:17.257110Z",
     "iopub.status.busy": "2022-11-13T20:31:17.256219Z",
     "iopub.status.idle": "2022-11-13T20:31:17.270982Z",
     "shell.execute_reply": "2022-11-13T20:31:17.270010Z"
    },
    "papermill": {
     "duration": 0.021828,
     "end_time": "2022-11-13T20:31:17.274367",
     "exception": false,
     "start_time": "2022-11-13T20:31:17.252539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviews</th>\n",
       "      <th>availability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, price, rating, reviews, availability]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a783084",
   "metadata": {
    "papermill": {
     "duration": 0.002496,
     "end_time": "2022-11-13T20:31:17.279698",
     "exception": false,
     "start_time": "2022-11-13T20:31:17.277202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29.139324,
   "end_time": "2022-11-13T20:31:17.903007",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-13T20:30:48.763683",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
